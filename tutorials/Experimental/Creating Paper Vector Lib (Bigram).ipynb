{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook assumes:\n",
    "1. You already have tokenized all the documents and stored them in SpaCy's Doc format on disk.\n",
    "2. You have trained a LDA model.\n",
    "\n",
    "This notebook will:\n",
    "\n",
    "1. load the required SpaCy Doc.\n",
    "2. fit (predict) the topics with LDA models.\n",
    "3. Save the result to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import gensim\n",
    "import nltk\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tn\n",
    "import os\n",
    "## Helpers\n",
    "\n",
    "def save_pkl(target_object, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(target_object, file)\n",
    "        \n",
    "def load_pkl(filename):\n",
    "    return pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "def save_json(target_object, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(target_object, file)\n",
    "        \n",
    "def load_json(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "In this step, we are going to load data from disk to the memory and properly format them so that we can processing them in the next \"preprocessing\" stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>submission_date</th>\n",
       "      <th>cover_url</th>\n",
       "      <th>full_url</th>\n",
       "      <th>first_page</th>\n",
       "      <th>last_page</th>\n",
       "      <th>pages</th>\n",
       "      <th>document_type</th>\n",
       "      <th>type</th>\n",
       "      <th>article_id</th>\n",
       "      <th>context_key</th>\n",
       "      <th>label</th>\n",
       "      <th>publication_title</th>\n",
       "      <th>submission_path</th>\n",
       "      <th>journal_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Role-play and Use Case Cards for Requirements ...</td>\n",
       "      <td>&lt;p&gt;This paper presents a technique that uses r...</td>\n",
       "      <td>2006-01-01T00:00:00-08:00</td>\n",
       "      <td>2009-02-26T07:42:10-08:00</td>\n",
       "      <td>http://aisel.aisnet.org/acis2001/1</td>\n",
       "      <td>http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>article</td>\n",
       "      <td>1001</td>\n",
       "      <td>742028</td>\n",
       "      <td>1</td>\n",
       "      <td>ACIS 2001 Proceedings</td>\n",
       "      <td>acis2001/1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Flexible Learning and Academic Performance in ...</td>\n",
       "      <td>&lt;p&gt;This research investigates the effectivenes...</td>\n",
       "      <td>2001-01-01T00:00:00-08:00</td>\n",
       "      <td>2009-02-26T22:04:53-08:00</td>\n",
       "      <td>http://aisel.aisnet.org/acis2001/10</td>\n",
       "      <td>http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>article</td>\n",
       "      <td>1006</td>\n",
       "      <td>744077</td>\n",
       "      <td>10</td>\n",
       "      <td>ACIS 2001 Proceedings</td>\n",
       "      <td>acis2001/10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Proactive Metrics: A Framework for Managing IS...</td>\n",
       "      <td>&lt;p&gt;Managers of information systems development...</td>\n",
       "      <td>2001-01-01T00:00:00-08:00</td>\n",
       "      <td>2009-02-26T22:03:31-08:00</td>\n",
       "      <td>http://aisel.aisnet.org/acis2001/11</td>\n",
       "      <td>http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>article</td>\n",
       "      <td>1005</td>\n",
       "      <td>744076</td>\n",
       "      <td>11</td>\n",
       "      <td>ACIS 2001 Proceedings</td>\n",
       "      <td>acis2001/11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Reuse in Information Systems Development: Clas...</td>\n",
       "      <td>&lt;p&gt;There has been a trend in recent years towa...</td>\n",
       "      <td>2001-01-01T00:00:00-08:00</td>\n",
       "      <td>2009-02-26T22:02:29-08:00</td>\n",
       "      <td>http://aisel.aisnet.org/acis2001/12</td>\n",
       "      <td>http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>article</td>\n",
       "      <td>1004</td>\n",
       "      <td>744075</td>\n",
       "      <td>12</td>\n",
       "      <td>ACIS 2001 Proceedings</td>\n",
       "      <td>acis2001/12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Improving Software Development: The Prescripti...</td>\n",
       "      <td>&lt;p&gt;We describe the Prescriptive Simplified Met...</td>\n",
       "      <td>2001-01-01T00:00:00-08:00</td>\n",
       "      <td>2009-02-26T22:01:24-08:00</td>\n",
       "      <td>http://aisel.aisnet.org/acis2001/13</td>\n",
       "      <td>http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>article</td>\n",
       "      <td>article</td>\n",
       "      <td>1003</td>\n",
       "      <td>744074</td>\n",
       "      <td>13</td>\n",
       "      <td>ACIS 2001 Proceedings</td>\n",
       "      <td>acis2001/13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Role-play and Use Case Cards for Requirements ...   \n",
       "1   2  Flexible Learning and Academic Performance in ...   \n",
       "2   3  Proactive Metrics: A Framework for Managing IS...   \n",
       "3   4  Reuse in Information Systems Development: Clas...   \n",
       "4   5  Improving Software Development: The Prescripti...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  <p>This paper presents a technique that uses r...   \n",
       "1  <p>This research investigates the effectivenes...   \n",
       "2  <p>Managers of information systems development...   \n",
       "3  <p>There has been a trend in recent years towa...   \n",
       "4  <p>We describe the Prescriptive Simplified Met...   \n",
       "\n",
       "            publication_date            submission_date  \\\n",
       "0  2006-01-01T00:00:00-08:00  2009-02-26T07:42:10-08:00   \n",
       "1  2001-01-01T00:00:00-08:00  2009-02-26T22:04:53-08:00   \n",
       "2  2001-01-01T00:00:00-08:00  2009-02-26T22:03:31-08:00   \n",
       "3  2001-01-01T00:00:00-08:00  2009-02-26T22:02:29-08:00   \n",
       "4  2001-01-01T00:00:00-08:00  2009-02-26T22:01:24-08:00   \n",
       "\n",
       "                             cover_url  \\\n",
       "0   http://aisel.aisnet.org/acis2001/1   \n",
       "1  http://aisel.aisnet.org/acis2001/10   \n",
       "2  http://aisel.aisnet.org/acis2001/11   \n",
       "3  http://aisel.aisnet.org/acis2001/12   \n",
       "4  http://aisel.aisnet.org/acis2001/13   \n",
       "\n",
       "                                            full_url first_page last_page  \\\n",
       "0  http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...                        \n",
       "1  http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...                        \n",
       "2  http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...                        \n",
       "3  http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...                        \n",
       "4  http://aisel.aisnet.org/cgi/viewcontent.cgi?ar...                        \n",
       "\n",
       "  pages document_type     type article_id context_key label  \\\n",
       "0             article  article       1001      742028     1   \n",
       "1             article  article       1006      744077    10   \n",
       "2             article  article       1005      744076    11   \n",
       "3             article  article       1004      744075    12   \n",
       "4             article  article       1003      744074    13   \n",
       "\n",
       "       publication_title submission_path  journal_id  \n",
       "0  ACIS 2001 Proceedings      acis2001/1           1  \n",
       "1  ACIS 2001 Proceedings     acis2001/10           2  \n",
       "2  ACIS 2001 Proceedings     acis2001/11           3  \n",
       "3  ACIS 2001 Proceedings     acis2001/12           4  \n",
       "4  ACIS 2001 Proceedings     acis2001/13           5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading metadata from trainning database\n",
    "con = sqlite3.connect(\"F:/FMR/data.sqlite\")\n",
    "db_documents = pd.read_sql_query(\"SELECT * from documents\", con)\n",
    "db_authors = pd.read_sql_query(\"SELECT * from authors\", con)\n",
    "data = db_documents # just a handy alias\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Journals\n",
    "We want to build a dedicated LDA model for each journal. So here we want to get a list of journal prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_name(s):\n",
    "    end = 0\n",
    "    for i in range(len(s.split('/')[0])):\n",
    "        try:\n",
    "            a = int(s[i])\n",
    "            end = i\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    return s[:end]\n",
    "\n",
    "journals = []\n",
    "for i in db_documents['submission_path']:\n",
    "    journals.append(get_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "journals = set(journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phraser, Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "import multiprocessing\n",
    "\n",
    "# Use tn(iter, desc=\"Some text\") to track progress\n",
    "def gen_tokenized_dict_beta(untokenized_dict):\n",
    "    gen1, gen2 = tee(untokenised.items())\n",
    "    ids = (id_ for (id_, text) in gen1)\n",
    "    texts = (text for (id_, text) in gen2)\n",
    "    docs = nlp.pipe(tn(texts, desc=\"Tokenization\", total=len(untokenized_dict)), n_threads=9)\n",
    "    tokenised = {id_: doc for id_, doc in zip(ids, docs)}\n",
    "    return tokenised\n",
    "\n",
    "def gen_tokenized_dict(untokenized_dict):\n",
    "    return {k: nlp(v) for k, v in tn(untokenized_dict.items(), desc=\"Tokenization\")}\n",
    "\n",
    "def gen_tokenized_dict_parallel(untokenized_dict): # Uses textblob\n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as executor:\n",
    "         return {num:sqr for num, sqr in tn(zip(untokenized_dict.keys(), executor.map(TextBlob, untokenized_dict.values())), desc=\"Tokenization\")}\n",
    "\n",
    "def keep_journal(dict_, journal):\n",
    "    kept = {k: v for k, v in tn(dict_.items(), desc=\"Journal Filter\") if k.startswith(journal)}\n",
    "    print(\"Original: \", len(dict_), \", Kept \", len(kept), \" items.\")\n",
    "    return kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from spacy.tokens.doc import Doc\n",
    "def save_doc_dict(d, folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "    nlp.vocab.dump_vectors(os.path.join(folder_name, 'vocab.bin'))\n",
    "    for k, v in tn(d.items(), desc=\"Saving doc\"):\n",
    "        k = k.replace('/', '-') + '.doc'\n",
    "        with open(os.path.join(folder_name, k), 'wb') as f:\n",
    "            f.write(v.to_bytes())\n",
    "            \n",
    "def load_doc_dict(folder_name):\n",
    "    nlp = spacy.load('en') # This is very important\n",
    "    file_list = glob.glob(os.path.join(folder_name, \"*.doc\"))\n",
    "    d = {}\n",
    "    nlp.vocab.load_vectors_from_bin_loc(os.path.join(folder_name, 'vocab.bin'))\n",
    "    for k in tn(file_list, desc=\"Loading doc\"):\n",
    "        with open(os.path.join(k), 'rb') as f:\n",
    "            k_ = k.split('\\\\')[-1].replace('-', '/').replace('.doc', '')\n",
    "            for bs in Doc.read_bytes(f):\n",
    "                d[k_] = Doc(nlp.vocab).from_bytes(bs)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_filter(l, pos=\"NOUN\"):\n",
    "    return [str(i.lemma_).lower() for i in l if i.pos_ == 'NOUN' and i.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigram(corpus):\n",
    "    phrases = Phrases(corpus)\n",
    "    make_bigram = Phraser(phrases)\n",
    "    return [make_bigram[i] for i in tn(corpus, desc='Bigram')], make_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 150\n",
    "chunksize = 2000\n",
    "passes = 1\n",
    "iterations = 150\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globdev already exists.\n",
      "icmb already exists.\n",
      "digit already exists.\n",
      "bled already exists.\n",
      "sais already exists.\n",
      "sighci already exists.\n",
      "Could not open binary file b'amcis\\\\vocab.bin'\n",
      "isd already exists.\n",
      "icdss already exists.\n",
      "iris already exists.\n",
      "sprouts_proceedings_siggreen_ already exists.\n",
      "wisp already exists.\n",
      "sbis already exists.\n",
      "mg already exists.\n",
      "ukais already exists.\n",
      "Could not open binary file b'ecis\\\\vocab.bin'\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "from imp import reload\n",
    "from os.path import exists\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def predict_journal(j):\n",
    "    corpus = load_doc_dict(j)\n",
    "    corpus = {k: pos_filter(v) for k, v in tn(corpus.items())}\n",
    "    \n",
    "    # Make it bigram\n",
    "    tokenised_list, make_bigram = bigram([i for i in corpus.values()])\n",
    "    \n",
    "    # Override the corpus\n",
    "    corpus = {k: make_bigram[i] for k, v in tn(corpus.items())}\n",
    "    dictionary = gensim.corpora.Dictionary.load(os.path.join(j, \"_noun_bigram.ldamodel.dictionary\"))\n",
    "    # dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=None)\n",
    "    if len(dictionary) < 10:\n",
    "        print(\"Warning: dictionary only has \" + str(len(dictionary)) + \" items. Passing.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Train LDA model.\n",
    "    from gensim.models import LdaModel\n",
    "    model = LdaModel.load(os.path.join(j, \"_noun_bigram_\" + str(num_topics) + \".ldamodel\"))\n",
    "    paper_vec_lib = {}\n",
    "    for paper_path, tokens in tn(corpus.items(), desc=\"Predicting\"):\n",
    "        bow = dictionary.doc2bow(tokens)\n",
    "        paper_vec_lib[paper_path] = model[bow]\n",
    "    save_json(paper_vec_lib, os.path.join(j, \"paper_vec_lib.json\"))\n",
    "    del dictionary, model\n",
    "\n",
    "journals = set([i for i in journals if i])\n",
    "for j in tn(journals, desc=\"Journal\"):\n",
    "    if not exists(os.path.join(j, \"paper_vec_lib.json\")):\n",
    "        try:\n",
    "            predict_journal(j)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(j, \"already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_paper_topic_lib(folder_name):\n",
    "    d = load_json(os.path.join(folder_name, \"paper_vec_lib.json\"))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digit_paper_topic_lib = load_paper_topic_lib('digit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['digit2015/3', 'digit2007/12', 'digit2008/5', 'digit2010/13', 'digit2004/4', 'digit2013/12', 'digit2007/7', 'digit2014/6', 'digit2006/6', 'digit2010/2', 'digit2008/3', 'digit2006/2', 'digit2015/10', 'digit2001/2', 'digit2007/9', 'digit2015/4', 'digit2003/3', 'digit2015/13', 'digit2013/4', 'digit2015/14', 'digit2002/2', 'digit2004/5', 'digit2005/4', 'digit2003/2', 'digit2003/4', 'digit2004/2', 'digit2013/11', 'digit2014/7', 'digit2015/11', 'digit2007/16', 'digit2013/8', 'digit2015/16', 'digit2007/14', 'digit2015/8', 'digit2009/6', 'digit2013/3', 'digit2006/3', 'digit2009/2', 'digit2014/9', 'digit2015/1', 'digit2013/2', 'digit2004/3', 'digit2008/9', 'digit2009/1', 'digit2008/6', 'digit2007/10', 'digit2015/5', 'digit2005/1', 'digit2015/2', 'digit2009/5', 'digit2008/7', 'digit2006/8', 'digit2007/4', 'digit2013/1', 'digit2010/11', 'digit2007/6', 'digit2009/10', 'digit2010/10', 'digit2006/5', 'digit2010/1', 'digit2010/15', 'digit2010/14', 'digit2014/4', 'digit2013/5', 'digit2002/1', 'digit2010/12', 'digit2004/7', 'digit2013/10', 'digit2014/10', 'digit2001/3', 'digit2001/1', 'digit2014/1', 'digit2009/4', 'digit2015/9', 'digit2007/17', 'digit2005/2', 'digit2003/1', 'digit2006/4', 'digit2013/6', 'digit2009/7', 'digit2013/9', 'digit2004/1', 'digit2015/7', 'digit2008/1', 'digit2010/5', 'digit2010/7', 'digit2007/11', 'digit2014/2', 'digit2009/3', 'digit2007/8', 'digit2009/9', 'digit2007/3', 'digit2014/8', 'digit2010/8', 'digit2010/3', 'digit2010/9', 'digit2010/6', 'digit2007/2', 'digit2015/12', 'digit2007/1', 'digit2007/15', 'digit2015/15', 'digit2005/3', 'digit2014/5', 'digit2009/11', 'digit2008/2', 'digit2014/3', 'digit2006/1', 'digit2010/4', 'digit2008/8', 'digit2006/7', 'digit2007/5', 'digit2007/13', 'digit2009/8', 'digit2015/6', 'digit2008/4', 'digit2004/6'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_paper_topic_lib.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18, 0.17483466083199492],\n",
       " [39, 0.3763245523057287],\n",
       " [73, 0.25043883246204185]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_paper_topic_lib['digit2008/4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the \n",
    "```\n",
    "# Topic, Confidence\n",
    "[[18, 0.17483466083199492],\n",
    " [39, 0.3763245523057287],\n",
    " [73, 0.25043883246204185]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "079fb16414014a5ca35c706bdb9be52f": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "0e5ccf347b7148fd9b1d6f68892d970d": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "22761ec7706847d2b097ab100b919728": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "276d239390fc49f690254207b29be21f": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "2e8a3a9b60d14ea1954513592de25ee9": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "2ed2a69ef071438fb73f0abe8b9db4fd": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "4e0d4f1d83b54e8c884b0cb5141acbd3": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "51b412675e3e4447933704ca5402e36b": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "5dd3532b133d491da32da75feefbabed": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "6352582d67ee4f1e9d0d8f7f9066b1d3": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "6aee7c6b865640299e22e62f9e0360a0": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "6f5b4e83fd1b45078c472558d2f0d56e": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "732802a3047d4c8ea3dd967bb59f4f09": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "78a8df1ffc7b49a79b94e3ccc4d8593e": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "7b041773e655421ea064e5a74a2c48d5": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "7fc9449fe79341d096b1d52b59a708ca": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "81d5254f0e4448ebad164856ae7dff83": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "82ddbae080124fb5831a90aa440ac1d6": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "86b06a0e357446138109459964c3029a": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "925005a541ba424f93d57b6ec6dc261b": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "93a336c328e04c4f8b031e75a3879d2e": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "952a4d505d9e4b158fcb316be477061c": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "988037fc7ccb43c78c4d06dbb27fd1e9": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "9e4d798a94674d11b2f562aafd9cc5b6": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "a008835f947646c993ee20d157f02715": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "b3bb24c1336f4685a2c3f0ebff28e182": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "b8b2e05b6e6b4507babf5a1883c4d80a": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "bd98cb9e7a8343ba8ad5259904496f4a": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "cf68258580b94756b62fded333076143": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "d14a5bacf6644f7d986aaffb8f15dad8": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "dcda25aaa5184e5b841041452c340dfc": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "de7c70a7876949b6b2de1ad3d931aa67": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "e4fe421aaac04812aa2d18ac990962d9": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "f0cd0af61f6e410f9b1f9b1a0ba7bf0c": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "f3bd0b79f993467b9656688cdf882325": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "f4413ec5c0774a6d88e48ca1dc6ea2ed": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
